{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk import wordpunct_tokenize\n",
    "import torch\n",
    "\n",
    "#import preprocessing file\n",
    "import pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp = {\n",
    "\"NAME\" : 1,\n",
    "\"CITATION\" : 2,\n",
    "\"COUNSEL\" : 3,\n",
    "\"JUDGE\" : 4,\n",
    "\"FACTS\" : 5,\n",
    "\"RLC\" : 6,\n",
    "\"REASONING\" : 7,\n",
    "\"ARG\" : 8,\n",
    "\"STATUTE\" : 9,\n",
    "\"PRECEDENT\" : 10,\n",
    "\"RPC\" : 11,\n",
    "\"ISSUE\" : 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "no_of_files = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.txt\n",
      "7.txt\n",
      "5.txt\n",
      "4.txt\n",
      "1.txt\n",
      "3.txt\n",
      "2.txt\n",
      "23.txt\n",
      "22.txt\n",
      "36.txt\n",
      "20.txt\n",
      "34.txt\n",
      "35.txt\n",
      "21.txt\n",
      "25.txt\n",
      "31.txt\n",
      "19.txt\n",
      "18.txt\n",
      "30.txt\n",
      "24.txt\n",
      "32.txt\n",
      "26.txt\n",
      "27.txt\n",
      "33.txt\n",
      "16.txt\n",
      "17.txt\n",
      "29.txt\n",
      "15.txt\n",
      "14.txt\n",
      "28.txt\n",
      "10.txt\n",
      "13.txt\n",
      "12.txt\n",
      "9.txt\n",
      "8.txt\n"
     ]
    }
   ],
   "source": [
    "csvFolderPath = '../labelled_data/'\n",
    "for filename in os.listdir(csvFolderPath):\n",
    "    print(filename[:-4] + '.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running file : 6.csv\n",
      "Running file : 7.csv\n",
      "Running file : 5.csv\n",
      "Running file : 4.csv\n",
      "Running file : 1.csv\n",
      "Running file : 3.csv\n",
      "Running file : 2.csv\n",
      "Running file : 23.csv\n",
      "Running file : 22.csv\n",
      "Running file : 36.csv\n",
      "Running file : 20.csv\n",
      "Running file : 34.csv\n",
      "Running file : 35.csv\n",
      "Running file : 21.csv\n",
      "Running file : 25.csv\n",
      "Running file : 31.csv\n",
      "Running file : 19.csv\n",
      "Running file : 18.csv\n",
      "Running file : 30.csv\n",
      "Running file : 24.csv\n",
      "Running file : 32.csv\n",
      "Running file : 26.csv\n",
      "Running file : 27.csv\n",
      "Running file : 33.csv\n",
      "Running file : 16.csv\n",
      "Running file : 17.csv\n",
      "Running file : 29.csv\n",
      "Running file : 15.csv\n",
      "Running file : 14.csv\n",
      "Running file : 28.csv\n",
      "Running file : 10.csv\n",
      "Running file : 13.csv\n",
      "Running file : 12.csv\n",
      "Running file : 9.csv\n",
      "Running file : 8.csv\n"
     ]
    }
   ],
   "source": [
    "csvFolderPath = '../labelled_data/'\n",
    "for filename in os.listdir(csvFolderPath):\n",
    "    print(f\"Running file : {filename}\")\n",
    "    annpath = os.path.join(csvFolderPath, filename)\n",
    "    df = pd.read_csv(annpath)\n",
    "    df = df.dropna(subset='Sentence',how='all')\n",
    "\n",
    "    #now each row in df has some value and are not empty\n",
    "    text = []\n",
    "    for index,row in df.iterrows():\n",
    "        text.append(row['Sentence'])\n",
    "    x.append(pp.preprocess(text))\n",
    "    \n",
    "    temp = []\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isna(row['Labels']):\n",
    "            dum = [0]\n",
    "        else:\n",
    "            dum = []\n",
    "            for word in wordpunct_tokenize(row['Labels']):\n",
    "                if word in asp:\n",
    "                    dum.append(asp[word])\n",
    "            if len(dum)==0:\n",
    "                dum.append(0)\n",
    "        temp.append(dum)\n",
    "    y.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    if len(x[i])!=len(y[i]):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save data to a pickle file\n",
    "with open('../intermediate/x.pickle', 'wb') as file:\n",
    "    pickle.dump(x, file)\n",
    "\n",
    "with open('../intermediate/y.pickle', 'wb') as file:\n",
    "    pickle.dump(y, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
