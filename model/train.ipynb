{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../intermediate/jgsvect.pickle','rb') as file:\n",
    "    jgsvect = pickle.load(file)\n",
    "with open('../intermediate/y.pickle','rb') as file:\n",
    "    y = pickle.load(file)\n",
    "with open('../intermediate/x.pickle','rb') as file:\n",
    "    x = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "jgsvect = [txt for jgs in jgsvect for txt in jgs]\n",
    "labels = [lst for jgs in y for lst in jgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp = {\n",
    "\"NAME\" : 1,\n",
    "\"CITATION\" : 2,\n",
    "\"COUNSEL\" : 3,\n",
    "\"JUDGE\" : 4,\n",
    "\"FACTS\" : 5,\n",
    "\"RLC\" : 6,\n",
    "\"REASONING\" : 7,\n",
    "\"ARG\" : 8,\n",
    "\"STATUTE\" : 9,\n",
    "\"PRECEDENT\" : 10,\n",
    "\"RPC\" : 11,\n",
    "\"ISSUE\" : 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {0 : 0, 1 : 0, 2 : 0, 3 : 0, 4 : 0, 5 : 0, 6 : 0, 7 : 0, 8 : 0, 9 : 0, 10 : 0, 11 : 0, 12 : 0}\n",
    "for i in range(0,len(labels)):\n",
    "    for label in labels[i]:\n",
    "        dict[label]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspect NAME : 12 sentences\n",
      "Aspect CITATION : 13 sentences\n",
      "Aspect COUNSEL : 28 sentences\n",
      "Aspect JUDGE : 15 sentences\n",
      "Aspect FACTS : 401 sentences\n",
      "Aspect RLC : 68 sentences\n",
      "Aspect REASONING : 665 sentences\n",
      "Aspect ARG : 44 sentences\n",
      "Aspect STATUTE : 87 sentences\n",
      "Aspect PRECEDENT : 104 sentences\n",
      "Aspect RPC : 98 sentences\n",
      "Aspect ISSUE : 15 sentences\n"
     ]
    }
   ],
   "source": [
    "for key in asp:\n",
    "    print(f\"Aspect {key} : {dict[asp[key]]} sentences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb.fit(labels)\n",
    "labels = mlb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.layers import SpatialDropout1D, Dropout\n",
    " \n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(10000,300,input_length=768))\n",
    "model.add(LSTM(units=100, input_shape=(768,1), return_sequences=True))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=13, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for vect in jgsvect:\n",
    "    temp.append(vect.numpy())\n",
    "X_final = temp.copy()\n",
    "\n",
    "X_final = np.array(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_final = labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_final))\n",
    "print(type(Y_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1741, 768) (1741, 13)\n"
     ]
    }
   ],
   "source": [
    "print(X_final.shape, Y_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_final,Y_final,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 768)\n",
      "(1392, 768)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 19s 407ms/step - loss: 2.2339 - accuracy: 0.3111 - val_loss: 1.9930 - val_accuracy: 0.3524\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 17s 397ms/step - loss: 1.9985 - accuracy: 0.3362 - val_loss: 2.0039 - val_accuracy: 0.3524\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 17s 398ms/step - loss: 2.0095 - accuracy: 0.3226 - val_loss: 2.0025 - val_accuracy: 0.3524\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 1.9971 - accuracy: 0.3384 - val_loss: 1.9938 - val_accuracy: 0.3524\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 1.9891 - accuracy: 0.3333 - val_loss: 2.0028 - val_accuracy: 0.3524\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 17s 397ms/step - loss: 1.9979 - accuracy: 0.3276 - val_loss: 1.9886 - val_accuracy: 0.3524\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 2.0039 - accuracy: 0.3254 - val_loss: 1.9903 - val_accuracy: 0.3524\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 1.9908 - accuracy: 0.3405 - val_loss: 1.9986 - val_accuracy: 0.3524\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 17s 396ms/step - loss: 2.0053 - accuracy: 0.3283 - val_loss: 1.9892 - val_accuracy: 0.3524\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 17s 397ms/step - loss: 2.0106 - accuracy: 0.3384 - val_loss: 1.9895 - val_accuracy: 0.3524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x299ed4c40>"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,validation_data=(X_test,Y_test),epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 113ms/step\n"
     ]
    }
   ],
   "source": [
    "# 3. Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1547631 , 0.00410143, 0.00577291, 0.01556682, 0.00667626,\n",
       "       0.2369559 , 0.04002809, 0.36337447, 0.02119171, 0.04380893,\n",
       "       0.05048272, 0.049382  , 0.00789566], dtype=float32)"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15346925, 0.00405928, 0.00569847, 0.01543377, 0.0066705 ,\n",
       "       0.23810655, 0.03986674, 0.3644772 , 0.02115727, 0.04370851,\n",
       "       0.05008907, 0.04940014, 0.00786333], dtype=float32)"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15208836, 0.00400935, 0.00562291, 0.01527784, 0.0066566 ,\n",
       "       0.23921125, 0.03968285, 0.36576614, 0.02110804, 0.04361974,\n",
       "       0.04972133, 0.04940495, 0.00783062], dtype=float32)"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on 1392 sentences\n",
      "Total number of sentences in test data : 349\n",
      "Number of sentences whose labels are present in top 1 predicted aspects for that sentence: 140 | accuracy : 40.11461318051576%\n",
      "Number of sentences whose labels are present in top 2 predicted aspects for that sentence: 197 | accuracy : 56.44699140401146%\n",
      "Number of sentences whose labels are present in top 3 predicted aspects for that sentence: 263 | accuracy : 75.35816618911174%\n",
      "Number of sentences whose labels are present in top 4 predicted aspects for that sentence: 286 | accuracy : 81.9484240687679%\n",
      "Number of sentences whose labels are present in top 5 predicted aspects for that sentence: 302 | accuracy : 86.53295128939828%\n",
      "Number of sentences whose labels are present in top 6 predicted aspects for that sentence: 314 | accuracy : 89.97134670487107%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model trained on {len(X_train)} sentences\")\n",
    "print(f\"Total number of sentences in test data : {len(X_test)}\")\n",
    "for i in range(1,7):\n",
    "    x = [np. argsort(temp)[::-1][:i] for temp in predictions]\n",
    "    indices_list = []\n",
    "\n",
    "    # Iterate through each binary vector\n",
    "    for binary_vector in Y_test:\n",
    "        # Use a list comprehension to get the indices of 1s\n",
    "        indices = [i for i, value in enumerate(binary_vector) if value == 1]\n",
    "        indices_list.append(indices)\n",
    "    \n",
    "    ispresent = []\n",
    "    for j in range(len(x)):\n",
    "        present = False\n",
    "        for label in indices_list[j]:\n",
    "            if label in x[j]:\n",
    "                present = True\n",
    "                break\n",
    "        if present:\n",
    "            ispresent.append(1)\n",
    "        else:\n",
    "            ispresent.append(0)\n",
    "    print(f\"Number of sentences whose labels are present in top {i} predicted aspects for that sentence: {np.sum(ispresent)} | accuracy : {np.sum(ispresent)*100/len(ispresent)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [np. argsort(temp)[::-1][:3] for temp in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 5, 0])"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 5, 0])"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../intermediate/test.pickle','rb') as file:\n",
    "    temp = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict((temp.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/meetbanthia/hale-internship/Legal-Document-Summarization-Meet/model/train.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/meetbanthia/hale-internship/Legal-Document-Summarization-Meet/model/train.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m predictions\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = [np. argsort(dum)[::-1][:1] for dum in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7]),\n",
       " array([7])]"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "asp = {\n",
    "\"NAME\" : 1,\n",
    "\"CITATION\" : 2,\n",
    "\"COUNSEL\" : 3,\n",
    "\"JUDGE\" : 4,\n",
    "\"FACTS\" : 5,\n",
    "\"RLC\" : 6,\n",
    "\"REASONING\" : 7,\n",
    "\"ARG\" : 8,\n",
    "\"STATUTE\" : 9,\n",
    "\"PRECEDENT\" : 10,\n",
    "\"RPC\" : 11,\n",
    "\"ISSUE\" : 12\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect = asp[\"FACTS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../intermediate/jgs.pickle','rb') as file:\n",
    "    jgs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(predict_judgements)):\n",
    "    if aspect in predicted_labels[i]:\n",
    "        print(jgs[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
